{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f90cd7a",
   "metadata": {},
   "source": [
    "## Rozdział 11: Hypertuning oraz Walidacja Krzyżowa\n",
    "\n",
    "### 11.1 Wprowadzenie\n",
    "\n",
    "W procesie uczenia maszynowego, dobór odpowiednich hiperparametrów oraz walidacja modeli są kluczowymi elementami wpływającymi na wydajność i dokładność modeli predykcyjnych. Hiperparametry to parametry zewnętrzne modelu, które muszą być ustawione przed procesem trenowania, natomiast walidacja krzyżowa to technika oceny modelu, która pozwala na lepsze oszacowanie jego wydajności na danych niewidocznych podczas trenowania.\n",
    "\n",
    "### 11.2 Hypertuning\n",
    "\n",
    "Hypertuning (dostrajanie hiperparametrów) to proces optymalizacji hiperparametrów modelu w celu poprawy jego wydajności. Hiperparametry różnią się w zależności od algorytmu i mogą obejmować takie wartości jak współczynnik uczenia, liczba warstw w sieci neuronowej, liczba drzew w lesie losowym, itp.\n",
    "\n",
    "#### 11.2.1 Rodzaje Hiperparametrów\n",
    "\n",
    "- **Hiperparametry modelu:** Bezpośrednio wpływają na sposób działania modelu, np. liczba neuronów w sieci neuronowej, głębokość drzewa decyzyjnego.\n",
    "- **Hiperparametry optymalizacji:** Wpływają na proces trenowania modelu, np. współczynnik uczenia w optymalizatorze gradient descent.\n",
    "\n",
    "#### 11.2.2 Techniki Hypertuningu\n",
    "\n",
    "- **Grid Search:** Przeszukiwanie przestrzeni hiperparametrów poprzez wypróbowanie wszystkich możliwych kombinacji z określonego zbioru wartości.\n",
    "- **Random Search:** Losowe przeszukiwanie przestrzeni hiperparametrów w określonym zakresie wartości.\n",
    "- **Bayesian Optimization:** Technika, która wykorzystuje modele probabilistyczne do efektywnego przeszukiwania przestrzeni hiperparametrów.\n",
    "- **Hyperband:** Algorytm, który adaptacyjnie przydziela zasoby do różnych zestawów hiperparametrów, przyspieszając proces tuningu.\n",
    "\n",
    "#### 11.2.3 Przykład Hypertuningu w Pythonie\n",
    "\n",
    "Przykładowy kod przedstawiający użycie Grid Search do dostrajania hiperparametrów w Pythonie przy użyciu biblioteki `scikit-learn`.\n",
    "\n",
    "```python\n",
    "# Importowanie bibliotek\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Załadowanie przykładowego zbioru danych - Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Definicja modelu\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Definicja przestrzeni hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Wyniki Grid Search\n",
    "print(f'Najlepsze hiperparametry: {grid_search.best_params_}')\n",
    "print(f'Najlepszy wynik dokładności: {grid_search.best_score_}')\n",
    "```\n",
    "\n",
    "### 11.3 Walidacja Krzyżowa\n",
    "\n",
    "Walidacja krzyżowa to technika oceny modelu, która pozwala na bardziej wiarygodne oszacowanie jego wydajności na danych niewidocznych podczas trenowania. Główną ideą jest podział danych na mniejsze części (foldy) i trenowanie modelu na jednej części, a następnie testowanie go na innej.\n",
    "\n",
    "#### 11.3.1 Typy Walidacji Krzyżowej\n",
    "\n",
    "- **K-Fold Cross-Validation:** Podział danych na \\(k\\) równych części. Model jest trenowany \\(k\\) razy, za każdym razem używając innego folda jako zestawu testowego, a pozostałe jako zestawu treningowego.\n",
    "- **Stratified K-Fold Cross-Validation:** Wariant K-Fold, który zapewnia, że proporcje klas są podobne w każdym foldzie, co jest ważne w przypadku danych z niezbalansowanymi klasami.\n",
    "- **Leave-One-Out Cross-Validation (LOOCV):** Skrajny przypadek K-Fold, gdzie \\(k\\) równa się liczbie próbek w zbiorze danych. Każda próbka jest używana jako zestaw testowy dokładnie raz.\n",
    "- **Repeated K-Fold Cross-Validation:** Powtarzanie K-Fold cross-validation wiele razy z różnymi losowymi podziałami danych.\n",
    "\n",
    "#### 11.3.2 Zalety i Wady Walidacji Krzyżowej\n",
    "\n",
    "**Zalety:**\n",
    "- **Lepsze oszacowanie wydajności modelu:** Większa niezawodność wyników w porównaniu do pojedynczego podziału na zbiór treningowy i testowy.\n",
    "- **Efektywne wykorzystanie danych:** Wszystkie próbki są używane zarówno do trenowania, jak i do testowania modelu.\n",
    "\n",
    "**Wady:**\n",
    "- **Wyższe koszty obliczeniowe:** Większa liczba trenowań modelu może być kosztowna obliczeniowo, zwłaszcza dla dużych zbiorów danych lub złożonych modeli.\n",
    "- **Potencjalne trudności w interpretacji wyników:** Konieczność analizy wyników z wielu trenowań i testów.\n",
    "\n",
    "#### 11.3.3 Przykład Walidacji Krzyżowej w Pythonie\n",
    "\n",
    "Przykładowy kod przedstawiający użycie K-Fold cross-validation w Pythonie przy użyciu biblioteki `scikit-learn`.\n",
    "\n",
    "```python\n",
    "# Importowanie bibliotek\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Załadowanie przykładowego zbioru danych - Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Definicja modelu\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5)\n",
    "\n",
    "# Definicja K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Ocena modelu przy użyciu K-Fold cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Wyniki walidacji krzyżowej\n",
    "print(f'Wyniki K-Fold Cross-Validation: {scores}')\n",
    "print(f'Średnia dokładność: {scores.mean()}')\n",
    "print(f'Odchylenie standardowe dokładności: {scores.std()}')\n",
    "```\n",
    "\n",
    "### 11.4 Połączenie Hypertuningu i Walidacji Krzyżowej\n",
    "\n",
    "Połączenie hypertuningu z walidacją krzyżową pozwala na bardziej wiarygodne oszacowanie wydajności modelu przy różnych zestawach hiperparametrów. Grid Search i Random Search mogą być używane w połączeniu z walidacją krzyżową, aby znaleźć optymalne hiperparametry modelu.\n",
    "\n",
    "#### 11.4.1 Przykład Połączenia Hypertuningu z Walidacją Krzyżową w Pythonie\n",
    "\n",
    "Przykładowy kod przedstawiający połączenie Grid Search z K-Fold cross-validation w Pythonie przy użyciu biblioteki `scikit-learn`.\n",
    "\n",
    "```python\n",
    "# Importowanie bibliotek\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Załadowanie przykładowego zbioru danych - Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Definicja modelu\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Definicja przestrzeni hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Definicja K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid Search z K-Fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kf, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Wyniki Grid Search z walidacją krzyżową\n",
    "print(f'Najlepsze hiperparametry: {grid_search.best_params_}')\n",
    "print(f'Najlepszy wynik dokładności: {grid_search.best_score_}')\n",
    "```\n",
    "\n",
    "### 11.5 Zakończenie\n",
    "\n",
    "Hypertuning i walidacja krzyżowa to kluczowe techniki w procesie tworzenia modeli uczenia maszynowego. Poprzez optymalizację hiperparametrów i bardziej wiarygodne oszacowanie wydajności modelu, te techniki pozwalają na tworzenie bardziej efektywnych i dokładnych modeli predykcyj\n",
    "\n",
    "nych. Połączenie tych technik może prowadzić do znaczącej poprawy wyników modeli, co jest niezbędne w wielu praktycznych zastosowaniach uczenia maszynowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790509a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
