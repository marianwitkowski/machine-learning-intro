{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e2228d",
   "metadata": {},
   "source": [
    "## Rozdział 3: Miary Wydajności Modelu\n",
    "\n",
    "### 3.1 Wprowadzenie\n",
    "\n",
    "Ocena wydajności modelu uczenia maszynowego jest kluczowa dla zrozumienia, jak dobrze model radzi sobie z zadaniem, do którego został stworzony. W zależności od rodzaju problemu (klasyfikacja, regresja, klasteryzacja), stosuje się różne miary wydajności. W tym rozdziale omówimy najważniejsze miary wydajności stosowane w modelach klasyfikacyjnych i regresyjnych.\n",
    "\n",
    "### 3.2 Miary Wydajności dla Klasyfikacji\n",
    "\n",
    "#### 3.2.1 Macierz Błędów\n",
    "\n",
    "Macierz błędów (confusion matrix) jest podstawowym narzędziem do oceny wydajności modelu klasyfikacyjnego. Składa się z czterech elementów:\n",
    "\n",
    "- **TP (True Positives)**: Liczba poprawnie sklasyfikowanych próbek pozytywnych.\n",
    "- **TN (True Negatives)**: Liczba poprawnie sklasyfikowanych próbek negatywnych.\n",
    "- **FP (False Positives)**: Liczba niepoprawnie sklasyfikowanych próbek negatywnych jako pozytywne.\n",
    "- **FN (False Negatives)**: Liczba niepoprawnie sklasyfikowanych próbek pozytywnych jako negatywne.\n",
    "\n",
    "#### 3.2.2 Dokładność (Accuracy)\n",
    "\n",
    "Dokładność to stosunek liczby poprawnych przewidywań (TP + TN) do całkowitej liczby próbek.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "#### 3.2.3 Precyzja (Precision)\n",
    "\n",
    "Precyzja to stosunek liczby poprawnie przewidywanych pozytywnych próbek (TP) do wszystkich próbek przewidywanych jako pozytywne (TP + FP).\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "#### 3.2.4 Czułość (Recall)\n",
    "\n",
    "Czułość, znana również jako True Positive Rate (TPR) lub Sensitivity, to stosunek liczby poprawnie przewidywanych pozytywnych próbek (TP) do wszystkich rzeczywistych pozytywnych próbek (TP + FN).\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "#### 3.2.5 F1-Score\n",
    "\n",
    "F1-Score jest średnią harmoniczną precyzji i czułości, zapewniającą równowagę między nimi.\n",
    "\n",
    "$$\n",
    "\\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "#### 3.2.6 Krzywa ROC i AUC\n",
    "\n",
    "Krzywa ROC (Receiver Operating Characteristic) ilustruje związek między True Positive Rate (TPR) a False Positive Rate (FPR) przy różnych progach decyzyjnych. AUC (Area Under the Curve) jest miarą wydajności modelu, gdzie wartość 1 oznacza idealny model, a 0.5 oznacza model losowy.\n",
    "\n",
    "### 3.3 Miary Wydajności dla Regresji\n",
    "\n",
    "#### 3.3.1 Średni Błąd Bezwarunkowy (Mean Absolute Error, MAE)\n",
    "\n",
    "MAE to średnia wartość bezwzględnych różnic między rzeczywistymi a przewidywanymi wartościami.\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} | y_i - \\hat{y_i} |\n",
    "$$\n",
    "\n",
    "#### 3.3.2 Średni Błąd Kwadratowy (Mean Squared Error, MSE)\n",
    "\n",
    "MSE to średnia wartość kwadratów różnic między rzeczywistymi a przewidywanymi wartościami. Jest bardziej wrażliwa na duże błędy niż MAE.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 \n",
    "$$\n",
    "\n",
    "#### 3.3.3 Pierwiastek Średniego Błędu Kwadratowego (Root Mean Squared Error, RMSE)\n",
    "\n",
    "RMSE to pierwiastek kwadratowy z MSE, dający miarę błędu w tych samych jednostkach, co dane.\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "$$\n",
    "\n",
    "#### 3.3.4 Współczynnik Determinacji (R²)\n",
    "\n",
    "R² mierzy, jaka część wariancji w danych jest wyjaśniana przez model. Wartość R² bliska 1 oznacza, że model dobrze wyjaśnia dane, natomiast wartość bliska 0 oznacza, że model nie wyjaśnia danych.\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n} (y_i - \\overline{y})^2} \n",
    "$$\n",
    "\n",
    "### 3.4 Porównanie Modeli\n",
    "\n",
    "Aby wybrać najlepszy model, często porównuje się ich wydajność za pomocą wspomnianych miar. Należy pamiętać, że różne miary mogą prowadzić do różnych wniosków w zależności od specyfiki problemu i danych.\n",
    "\n",
    "### 3.5 Wybór Miary Wydajności\n",
    "\n",
    "Wybór odpowiedniej miary wydajności zależy od specyficznych wymagań projektu:\n",
    "\n",
    "- W przypadku klasyfikacji z niezbalansowanymi danymi precyzja, czułość i F1-Score mogą być bardziej informatywne niż dokładność.\n",
    "- W przypadku regresji MAE może być bardziej odpowiednia, gdy istotne są jednostkowe różnice, natomiast RMSE może być lepsza, gdy duże błędy są szczególnie istotne.\n",
    "\n",
    "### 3.6 Zakończenie\n",
    "\n",
    "Miary wydajności są nieodzownym elementem każdego projektu uczenia maszynowego. Pozwalają one na obiektywną ocenę modelu i jego porównanie z innymi podejściami. Zrozumienie i właściwe stosowanie tych miar jest kluczowe dla tworzenia skutecznych i niezawodnych modeli uczenia maszynowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48ae91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
