{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc6d7d2",
   "metadata": {},
   "source": [
    "## Rozdział 10: Normalizacja Danych w Uczeniu Maszynowym\n",
    "\n",
    "### 10.1 Wprowadzenie\n",
    "\n",
    "Normalizacja danych jest kluczowym krokiem w procesie przygotowania danych do uczenia maszynowego. Polega na przekształceniu danych w taki sposób, aby miały one podobne skale, co ma na celu poprawę wydajności i stabilności modeli. Normalizacja jest szczególnie ważna w przypadku algorytmów wrażliwych na skalę danych, takich jak metody bazujące na odległościach (np. k-NN) czy sieci neuronowe.\n",
    "\n",
    "### 10.2 Dlaczego Normalizacja Jest Ważna?\n",
    "\n",
    "- **Skalowanie Ceł:** Algorytmy uczenia maszynowego, takie jak regresja liniowa, SVM, i sieci neuronowe, często działają lepiej, gdy cechy mają podobne skale. Normalizacja zapobiega dominacji cech o dużych wartościach nad cechami o mniejszych wartościach.\n",
    "- **Szybsza Konwergencja:** Normalizacja może przyspieszyć proces trenowania modeli, szczególnie w algorytmach optymalizacyjnych, takich jak gradient descent, gdzie zbieżność może być szybsza, gdy dane są znormalizowane.\n",
    "- **Unikanie Błędów Numerycznych:** Normalizacja pomaga w unikaniu problemów numerycznych podczas obliczeń, które mogą wynikać z bardzo dużych lub bardzo małych wartości cech.\n",
    "\n",
    "### 10.3 Techniki Normalizacji Danych\n",
    "\n",
    "#### 10.3.1 Min-Max Scaling\n",
    "\n",
    "Min-Max Scaling polega na przekształceniu danych do określonego przedziału, zwykle [0, 1] lub [-1, 1]. Wzór na przekształcenie Min-Max to:\n",
    "\n",
    "$ x' = \\frac{x - \\text{min}(x)}{\\text{max}(x) - \\text{min}(x)} $\n",
    "\n",
    "#### 10.3.2 Standaryzacja (Z-score Normalization)\n",
    "\n",
    "Standaryzacja polega na przekształceniu danych tak, aby miały one średnią równą zero i odchylenie standardowe równe jeden. Wzór na standaryzację to:\n",
    "\n",
    "$ x' = \\frac{x - \\mu}{\\sigma} $\n",
    "\n",
    "gdzie $ \\mu $ to średnia, a $ \\sigma $ to odchylenie standardowe.\n",
    "\n",
    "#### 10.3.3 Normalizacja Maksymalna\n",
    "\n",
    "Normalizacja maksymalna polega na podzieleniu każdej wartości przez maksymalną wartość w danej kolumnie:\n",
    "\n",
    "$ x' = \\frac{x}{\\text{max}(x)} $\n",
    "\n",
    "#### 10.3.4 Normalizacja L2\n",
    "\n",
    "Normalizacja L2 polega na przekształceniu wektora cech tak, aby jego długość (norma L2) była równa jeden:\n",
    "\n",
    "$ x' = \\frac{x}{\\|x\\|_2} $\n",
    "\n",
    "### 10.4 Przykład Implementacji Normalizacji w Pythonie\n",
    "\n",
    "Przykładowy kod przedstawiający różne techniki normalizacji w Pythonie przy użyciu biblioteki `scikit-learn`.\n",
    "\n",
    "```python\n",
    "# Importowanie bibliotek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "# Załadowanie przykładowego zbioru danych - Iris\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data_min_max_scaled = pd.DataFrame(min_max_scaler.fit_transform(data), columns=iris.feature_names)\n",
    "\n",
    "# Standaryzacja\n",
    "standard_scaler = StandardScaler()\n",
    "data_standard_scaled = pd.DataFrame(standard_scaler.fit_transform(data), columns=iris.feature_names)\n",
    "\n",
    "# Normalizacja Maksymalna\n",
    "max_scaler = lambda x: x / np.max(np.abs(x), axis=0)\n",
    "data_max_scaled = data.apply(max_scaler, axis=0)\n",
    "\n",
    "# Normalizacja L2\n",
    "normalizer = Normalizer(norm='l2')\n",
    "data_l2_normalized = pd.DataFrame(normalizer.fit_transform(data), columns=iris.feature_names)\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Oryginalne Dane:\\n\", data.head())\n",
    "print(\"\\nMin-Max Scaling:\\n\", data_min_max_scaled.head())\n",
    "print(\"\\nStandaryzacja:\\n\", data_standard_scaled.head())\n",
    "print(\"\\nNormalizacja Maksymalna:\\n\", data_max_scaled.head())\n",
    "print(\"\\nNormalizacja L2:\\n\", data_l2_normalized.head())\n",
    "```\n",
    "\n",
    "### 10.5 Zalety i Wady Normalizacji Danych\n",
    "\n",
    "#### 10.5.1 Zalety\n",
    "\n",
    "- **Lepsza Wydajność Modelu:** Normalizacja może poprawić wydajność wielu algorytmów uczenia maszynowego.\n",
    "- **Szybsze Trenowanie:** Normalizacja może przyspieszyć proces trenowania modeli.\n",
    "- **Stabilność Obliczeń:** Normalizacja pomaga w unikaniu problemów numerycznych.\n",
    "\n",
    "#### 10.5.2 Wady\n",
    "\n",
    "- **Utrata Informacji:** W niektórych przypadkach normalizacja może prowadzić do utraty istotnych informacji.\n",
    "- **Potrzeba Ponownej Normalizacji:** Dane testowe muszą być normalizowane w ten sam sposób co dane treningowe.\n",
    "- **Nie Zawsze Konieczna:** Normalizacja nie jest konieczna dla wszystkich algorytmów, na przykład drzewa decyzyjne nie są wrażliwe na skalę danych.\n",
    "\n",
    "### 10.6 Zastosowania Normalizacji Danych\n",
    "\n",
    "#### 10.6.1 Przetwarzanie Obrazów\n",
    "\n",
    "W przetwarzaniu obrazów normalizacja jest często stosowana do skalowania pikseli do określonego przedziału, co poprawia wydajność sieci neuronowych.\n",
    "\n",
    "#### 10.6.2 Analiza Genetyczna\n",
    "\n",
    "W analizie genetycznej normalizacja jest używana do przekształcania danych o różnych skalach na porównywalne skale.\n",
    "\n",
    "#### 10.6.3 Systemy Rekomendacyjne\n",
    "\n",
    "W systemach rekomendacyjnych normalizacja jest stosowana do przekształcania ocen użytkowników na porównywalne skale, co ułatwia analizę preferencji.\n",
    "\n",
    "### 10.7 Zakończenie\n",
    "\n",
    "Normalizacja danych jest kluczowym krokiem w przygotowaniu danych do uczenia maszynowego, który może znacząco poprawić wydajność i stabilność modeli. Dzięki różnym technikom normalizacji, takim jak Min-Max Scaling, standaryzacja, normalizacja maksymalna i normalizacja L2, można skutecznie przekształcać dane na porównywalne skale. Mimo że normalizacja ma swoje wady, jej zalety sprawiają, że jest nieodzownym narzędziem w arsenale analityka danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fa0b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oryginalne Dane:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "Min-Max Scaling:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222          0.625000           0.067797          0.041667\n",
      "1           0.166667          0.416667           0.067797          0.041667\n",
      "2           0.111111          0.500000           0.050847          0.041667\n",
      "3           0.083333          0.458333           0.084746          0.041667\n",
      "4           0.194444          0.666667           0.067797          0.041667\n",
      "\n",
      "Standaryzacja:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.900681          1.019004          -1.340227         -1.315444\n",
      "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
      "2          -1.385353          0.328414          -1.397064         -1.315444\n",
      "3          -1.506521          0.098217          -1.283389         -1.315444\n",
      "4          -1.021849          1.249201          -1.340227         -1.315444\n",
      "\n",
      "Normalizacja Maksymalna:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.645570          0.795455           0.202899              0.08\n",
      "1           0.620253          0.681818           0.202899              0.08\n",
      "2           0.594937          0.727273           0.188406              0.08\n",
      "3           0.582278          0.704545           0.217391              0.08\n",
      "4           0.632911          0.818182           0.202899              0.08\n",
      "\n",
      "Normalizacja L2:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.803773          0.551609           0.220644          0.031521\n",
      "1           0.828133          0.507020           0.236609          0.033801\n",
      "2           0.805333          0.548312           0.222752          0.034269\n",
      "3           0.800030          0.539151           0.260879          0.034784\n",
      "4           0.790965          0.569495           0.221470          0.031639\n"
     ]
    }
   ],
   "source": [
    "# Importowanie bibliotek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "# Załadowanie przykładowego zbioru danych - Iris\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data_min_max_scaled = pd.DataFrame(min_max_scaler.fit_transform(data), columns=iris.feature_names)\n",
    "\n",
    "# Standaryzacja\n",
    "standard_scaler = StandardScaler()\n",
    "data_standard_scaled = pd.DataFrame(standard_scaler.fit_transform(data), columns=iris.feature_names)\n",
    "\n",
    "# Normalizacja Maksymalna\n",
    "max_scaler = lambda x: x / np.max(np.abs(x), axis=0)\n",
    "data_max_scaled = data.apply(max_scaler, axis=0)\n",
    "\n",
    "# Normalizacja L2\n",
    "normalizer = Normalizer(norm='l2')\n",
    "data_l2_normalized = pd.DataFrame(normalizer.fit_transform(data), columns=iris.feature_names)\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Oryginalne Dane:\\n\", data.head())\n",
    "print(\"\\nMin-Max Scaling:\\n\", data_min_max_scaled.head())\n",
    "print(\"\\nStandaryzacja:\\n\", data_standard_scaled.head())\n",
    "print(\"\\nNormalizacja Maksymalna:\\n\", data_max_scaled.head())\n",
    "print(\"\\nNormalizacja L2:\\n\", data_l2_normalized.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df93eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
